#+TITLE: Bug-induced Upgrade
#+DATE:
#+AUTHOR: wuxh
#+OPTIONS: timestamp:nil
#+OPTIONS: ^:{}
#+OPTIONS: ':t
#+HTML_HEAD_EXTRA: <style type="text/css">body{font-family:"Iowan Old Style","Palatino","Linux Libertine","Georgia", serif;} code, kbd, pre, samp {font-family: Monaco, Consolas, "Cascadia Code", "Fira Mono", "Fira Code", monospace} blockquote {margin: 1em 2em; padding-left: 1em; border-left: 3px solid #ccc} </style>



* Overview
** Goal
   There exist some library upgrade which would break client. Among them lots of cases are due to
   the co-evolution of libraries. We aim to find those bug-induced upgrade.

   Given a client (and its dependencies), generate a patch on POM to upgrade a certain library /
   certain libraries, so that some client tests (used to pass) would fail with upgraded
   dependencies.

** NaÃ¯ve approach / groundtruth
   Upgrade each library and run tests.
   Our approach should be more efficient than this brute-force approach.
** Current idea
   To reduce the cycles of upgrade-runtest,
   cluster / partition all dependencies (maybe include transitive) as weakly-connected (directed) sub-graphs,
   so that multiple combinations can be pruned after one upgrade-runtest cycle.

** Algorithm
   #+begin_src C
// INPUT: c - a client
D_a = DependencyGraph(c) // pom
D_b = RunAnalysis() // codeQL query
G = ConstructGraph(D_a, D_b)
G_0, ..., G_n = Partition(G) // a set of sub-graphs
While (any of G_i is not empty) do
    For i = 0 to n do
	L_i = Prioritise(G_i)
    done
    DoUpgrade([L_i for i = 0 to n])
    T = SelectTest()
    suc, trace = RunTest(T)
    if suc is false then
	if Verify(trace) is true then
	    return
    else
	Prune(G_0, ..., G_n)
done
   #+end_src

** How to reduce search space

** Client issues
* Partition strategy / ideas
** Mine references used in POMs
   Those library whose versions are configured use the same reference should have strong
   connection.
** Static analysis on client
   Find highly-related libraries, based on their mutual presence and/or data dependency in a
   client method.

* Interaction Pattern (where conflicts happen)
+ JAR ?
+ POM:
+ data: e.g. jacoco-core, jacoco-report
+ client usage
* Future Plan
+ Upgrade pairs to find conflicts caused by two (or more) dependencies


* Maven Dependency Plugin
** Verbose option
   =-Dverbose= option was removed since =maven-dependency-plugin:3.0= for Maven 3 compatibility.
** copy-dependency

** unpack-dependencies
   We could use this option to directly unpack jars instead of doing it manually.

* Dataflow Analysis with CodeQL
** Step
#+begin_src sh
codeql database create project.db --language=java
codeql database analyze project.db ~/codeql-repo/java/ql/src/datadp.ql  --output=/tmp/a.csv --format=csv
codeql bqrs decode --format=csv -o project.csv project.db/results/codeql-java/datadp.bqrs
#+end_src
** Current issues (but can be solved in the merging step)
   + [X] Not filter client class: can do it in the later steps
   + [ ] Filter java std lib (why =notJavaLib/1= is not applied on =isSink/1=)
   + [X] Not work when using codeql command line tools (path-problem result patterns?)
	 - refer to [[#manual-decode-bqrs]] for solutions
   + [ ] Can =notSameJar/2= be improved?

** How to get query results with CLT
   :PROPERTIES:
   :CUSTOM_ID: manual-decode-bqrs
   :END:
   When the query does not conform with the format of path query, =interpret-results= does not work.
   However, we can always invoke =bqrs decode --format=csv -o results.csv datadp.bqrs=, generating a
   CSV of query results.

** CodeQL Dataflow Analysis for Java
   Refer to [[https://codeql.github.com/docs/codeql-language-guides/analyzing-data-flow-in-java/][CodeQL Java Guide: analyzing-data-flow]]

   + =java.dataflow.DataFlow= implements *local* dataflow analysis
   + =java.dataflow.DataFlow::Configuration= implements *global* dataflow analysis
   + =java.dataflow.TaintTracking= implements *local* taint tracking
	 - the analysis is performed using predicate =TaintTracking::localTaint(Dataflow::Node, Dataflow::Node)=
	 - the predicate is actually a transitive closure of =localTaintStep/2=
   + =java.dataflow.TaintTracking::Configuration= implements *global* taint tracking
	 - the analysis is performed using predicate =hasFlow(Dataflow::Node, Dataflow::Node)=
** Precision

* Add dataflow analysis results in pomdep graph
** Multiple G-A-V in one JAR
   + (fuzzy) match class path against group_id/artifact_id
     - now: split by dot and do set intersection (class_name in csv ^ class_path in JAR)
** On determining Mvn-Coord of a JAR
   + Some JAR do not include =pom.properties=
   + Some JAR do not include =META-INF= directory, at least =MANIFEST.MF= can be used to determine artifact id
   + If found nothing, just use the JAR name
	 - [ ] can at least prune version string

** Match coord with nodes in pomdep graph
   + full match (g,a,v) first
   + if failed, match artifact_id only
   + if failed, skip


* Class-level graph
  + [ ] Classes in which package
  + [ ] Class reference: datalog


* Cases Inspection
** java-driver
   + On the target version (tag =4.3.0=), expected dependency
   =slf4j.LoggerFactory -> logback.classic.Logger= does not appear in
   codeql query results.

   + Modify query script with location report.

   + Try to checkout to newer version =4.9.0=, run the same query again,
   found similar dependency in another file.

[[file:../../cases/java-driver-again/core/src/test/java/com/datastax/oss/driver/internal/core/util/LoggerTest.java][java-driver:4.9.0 LoggerTest]]
#+begin_src java
// 4.9.0 (023278b183e48b2d515b6b85c54e5f446a7addb9)
// core/src/test/java/com/datastax/oss/driver/internal/core/util/LoggerTest.java
public static LoggerSetup setupTestLogger(Class<?> clazz, Level levelToCapture) {
  @SuppressWarnings("unchecked")
  Appender<ILoggingEvent> appender = (Appender<ILoggingEvent>) mock(Appender.class);

  ArgumentCaptor<ILoggingEvent> loggingEventCaptor = ArgumentCaptor.forClass(ILoggingEvent.class);
  Logger logger = (Logger) LoggerFactory.getLogger(clazz); // line no: 33
  Level originalLoggerLevel = logger.getLevel();
  logger.setLevel(levelToCapture);
  logger.addAppender(appender); // line no: 36
  return new LoggerSetup(appender, originalLoggerLevel, logger, loggingEventCaptor);
}
#+end_src

which results in:
#+begin_src
"mock(...)","org.mockito.Mockito","addAppender(...)","ch.qos.logback.classic.Logger","LoggerTest:30[66-85]","LoggerTest:36[24-31]"
"getLogger(...)","org.slf4j.LoggerFactory","getLevel(...)","ch.qos.logback.classic.Logger","LoggerTest:33[30-59]","LoggerTest:34[33-38]"
"getLogger(...)","org.slf4j.LoggerFactory","setLevel(...)","ch.qos.logback.classic.Logger","LoggerTest:33[30-59]","LoggerTest:35[5-10]"
"getLogger(...)","org.slf4j.LoggerFactory","addAppender(...)","ch.qos.logback.classic.Logger","LoggerTest:33[30-59]","LoggerTest:36[5-10]"
"getLevel(...)","ch.qos.logback.classic.Logger","new LoggerSetup(...)","com.datastax.oss.driver.internal.core.util.LoggerTest$LoggerSetup","LoggerTest:34[33-49]","LoggerTest:37[38-56]"
#+end_src


But the following code (=DefaultLoadBalancingPolicyTestBase.java=) in both versions did not result in a record in query results:
[[file:../../cases/java-driver-430/core/src/test/java/com/datastax/oss/driver/internal/core/loadbalancing/DefaultLoadBalancingPolicyTestBase.java][java-driver:4.3.0 LoggerTest]]
#+begin_src java
// 4.3.0 (4af0061baabe1bcc03a9a6eea0028c12a6bd2e88)
// core/src/test/java/com/datastax/oss/driver/internal/core/loadbalancing/DefaultLoadBalancingPolicyTestBase.java
@Before
  public void setup() {
    ...
    logger =
        (Logger) LoggerFactory.getLogger("com.datastax.oss.driver.internal.core.loadbalancing");
    logger.addAppender(appender);  // line no: 81
    ...
  }
#+end_src

*** WAIT Differences of those two code snippets
	+ In the /not-captured/ code, =logger= and =appender= was declared and initialized through
	  mocking outside of the method.
	  And in the successfully recognized example, both are local variables.
	  Note that in CodeQL we already use a global taint tracking.

	+ Using a test script (see [[codeql-test][below]], we can confirm that 2 (different) qualified
    names are correctly recognized. The problem seems to stem from codeql's =hasFlow/2=.

*** Remove JUnit decorators
	We try to remove JUnit annotations.

**** Remove @Before only
	 Running the following script in =java-driver/core=.
	 #+begin_src sh
rg -l '\s+@Before' -t java | xargs -I '{}'  sed -i -r -e 's/^(\s+)(@Before)/\1\/\/\2/g' {}
	 #+end_src
	 It may trigger some errors from format-enforcing plugin, can be resolved by run code formatting.

	 Then it still lead to build failure.
	 #+begin_src
[JUnit4SetUpNotRun] setUp() method will not be run; please add JUnit's @Before annotation
	 #+end_src



** chaos-monkey-spring-boot
#+begin_src java
@Before
public void setUp() {
	ch.qos.logback.classic.Logger root = (ch.qos.logback.classic.Logger) LoggerFactory.getLogger(ch.qos.logback.classic.Logger.ROOT_LOGGER_NAME);
	root.addAppender(mockAppender);

	captorLoggingEvent = ArgumentCaptor.forClass(LoggingEvent.class);
}
#+end_src

A simple codeql program (see [[codeql-test][below]]) for testing show that the code got processed and class names are
recognized correctly.

#+NAME: codeql-test
#+begin_src sql
import java
from Call a, Expr s, Location sl
where s = a.getQualifier() and sl = s.getLocation()
select a.getCallee().getDeclaringType().getQualifiedName(), s, sl
#+end_src

#+begin_src
"org.slf4j.LoggerFactory","LoggerFactory","KillAppAssaultTest:51[78-90]"
"ch.qos.logback.classic.Logger","root","KillAppAssaultTest:52[9-12]"
#+end_src

It seems that JUnit annotations interfere with dataflow analysis of CodeQL.
Following is a change which would make the codeql program for dataflow detection work.
#+begin_src diff
@@ -46,7 +46,7 @@ public class KillAppAssaultTest {
     @Mock
     private MetricEventPublisher metricsMock;

-    @Before
+    // @Before
     public void setUp() {
         ch.qos.logback.classic.Logger root = (ch.qos.logback.classic.Logger) LoggerFactory.getLogger(ch.qos.logback.classic.Logger.ROOT_LOGGER_NAME);
         root.addAppender(mockAppender);
@@ -54,8 +54,9 @@ public class KillAppAssaultTest {
         captorLoggingEvent = ArgumentCaptor.forClass(LoggingEvent.class);
     }

-    @Test
+    // @Test
     public void killsSpringBootApplication() {
+        setUp();
         KillAppAssault killAppAssault = new KillAppAssault(null, metricsMock);
         killAppAssault.attack();
#+end_src


** Current Solution
   Use =DataFlow::Configuration= instead of =TaintTracking::Configuration=.
   Refer to [[https://github.com/github/codeql/issues/5511][github/codeql:issue:5511]].

*** What are the differences?
	Compared with =DataFlow::Configuration=, the =TaintTracking::Configuration= extends global
	dafaflow by including non-value-preserving flow steps.

* TODO Version Conflicts Discovery
** Track change history of library



* Run on all cases

** Column explanation
*** not_empty_result
	+ no: means there are pairs
	+ yes: empty result
	+ not-found: not in the JSON file
	+ error: failed in batch run
*** co_evo_found
	+ yes: almost the same with doc
	+ no: no result
	+ possible: related
	+ maybe: not related but could be
	+ not-likely: nearly impossible
** Issues
   + Few failed for facts collection, need inspection
   + some in google docs not shown in incompat-pairs-all.json
   + some results could indicate indirect dep (A,B,C -> D)
   + logging library slf4j appears often, possibly due to that usage convention in tests



* Dependabot
  So that we can show to developers that we can reveal the cause of unresolved conflicts in PR.

** General
   Three types:
   + Dependabot Alert: security alerts for vulnerable dependencies
   + Dependabot Security Updates: automated security updates
   + Version Updates: automated version updates even if there is no known vulnerabilities

** Search issues/pr on github using break as keyword
   We search all PRs made by dependabot in repos which also contain "break" in comments.
   #+begin_src sh
curl -H "Accept: application/vnd.github.v3+json" \
	 'https://api.github.com/search/issues?q=break+in:comments+is:pr+author:app/dependabot+language:java&sort=created&order=desc&per_page=100&page=1'
   #+end_src

   We insepcted them.
   Using python script to automated change page numbers (~page=1~) and we found 167 in total.

*** CANCELED quarkusio/quarkus/pr/16500
	merged, "breaking" used to describe changes in library
*** WAIT cloudyrock/mongock-integration-tests/pull/14
	"No merged because it's breaking the maven build."

	It is not an independent project, but tests for another project.

*** WAIT hashgraph/hedera-mirror-node/pull/1840
	hard-to-build.

	=invalid target release: 11=
	possible reason:
	=os.detected.release.version: 11=
	because the host is debian sid.

	Will try to use docker to build.

	Using docker, there are lots of test failures. It seems that the testing process itself would
	use docker to start applications.

	It would be rather difficult to test this project.


*** CANCELED mybatis/generator/pull/686
	requires Java 11

*** CANCELED mybatis/mybatis-dynamic-sql/pull/341
	requires Java 11

*** WAIT mozilla/gcp-ingestion/pull/1640
	need to inspect test failures

*** CANCELED ArDoCo/Core/pull/8
    not interesting, merged after simple configuration changes

*** WAIT exercism/java/pull/1916
	#+begin_quote
	approved for me, I found some migration requirements from action v1 to v2 and I commited them in
	this PR. This is a possible breaking PR.
	#+end_quote

	It is an upgrade to github actions instead of ordinary 3rd party java libraries.
	And devs commit an initial fix by only updating =.github/workflows/gradle.yml=.
	Ignored for now.

*** WAIT oshi/oshi/pull/1599
	It is also an upgrade to versions of github actions.

*** WAIT junit-platform-maven-plugin/pull/65
	It is also an upgrade to versions of github actions.
*** WAIT jeremylong/DependencyCheck/pull/3259
	It is also an upgrade to versions of github actions.
*** WAIT hashgraph/hedera-mirror-node/pull/1799
	This project again, hard to test.
	And likely configuration related.
	#+begin_quote
	there is breaking change in v6.0.0 so the way husky is configured in our project most likely
	needs update.
	#+end_quote

*** TODO appng
**** Reproduce
	 [[https://github.com/appNG/appng/pull/92][pull/92]]

	 Encounter an error at first, check =CONTRIBUTING.adoc= and
	 https://stackoverflow.com/questions/23011547/webservice-client-generation-error-with-jdk8.

	 Need to pass =-Djavax.xml.accessExternalSchema=all= for Java 8+.

	 Comments from dev (reason not upgrading):
	 #+begin_quote
	 Can not do because of dependency to Apache POI 4.x, would break backwards compatibility!
	 #+end_quote

	 Building and testing from version /appng-1.20.0/ triggered some errors,
	 some of which could be caused by using Java 8.

	 We switch to the main branch and redo the process. (newest version of appng still does not
	 upgrade tika)

	 Firstly do not upgrade, and ensure we can build successfully by skipping those tests failling
	 due to various reasons:
	 + timezones: there would be 6/7 hours shift in tests involving time depending on summer/winter
	   (authors seem to be in CST/CEST, verified: Germany)
	   + By setting time zone to a CET/CEST district (e.g., Europe/Zurich, Europe/Berlin), some
		 issues will disapper.
	   + Still the following failed. Under CST/CEST, it should be UTC+1 when it is 2012-12-12 (winter
		 obviously), so when using a GMT+3 timezone, the time would be =15:14:15= with a 2-hours
		 shift. But the test failed because program returns =16:14:15=. It seems that
		 =SimpleDataFormat.parse()= treat it as a UTC time. Since the documentation states
		 =java.text.SimpleDateFormat= is /locale-sensitive/, so we also try to set =LC_TIME= to a
		 suitable timezone such as 'de_CH.utf8'. But it still failed with the same output.
		 #+begin_src java
 p.setBirthDate(new SimpleDateFormat(pattern).parse("2012.12.12 13:14:15"));
 Mockito.when(request.getExpressionEvaluator())
	 .thenReturn(new ExpressionEvaluator(new HashMap<>()));
 Mockito.when(env.getTimeZone()).thenReturn(TimeZone.getTimeZone("GMT+3"));
		 #+end_src
	   + The temp workaround is to just exclude certain tests.

**** Errors or Failures

*** openmrs-contrib-addonindex
	[[https://github.com/openmrs/openmrs-contrib-addonindex/pull/68][pull/68]]

	Cannot re-produce.


** Search most commented PRs opened by dependabot
   If filtered by state:open, then there are only very few opened PRs with many comments.
   So we should include closed / merged ones when inspecting PRs.

   And according to the inspection, number of comments cannot be used as a good indicator of
   valuable PRs due to bots can be sometimes very chatty and having too many comments sometimes
   indicates a casual repo.

*** Dependabot talks alone
   The most commented one is an issue where the dependabot repeatedly stating "trying to upgrade but
   something went wrong" until a developer closed the issue. It seems due to the deletion of the
   directory where the dependency resided in. See [[https://github.com/expo/expo/pull/9508][expo/expo/pull/9508]].

   The other most commented ones are similar, with repeated comments produced by dependabot.

*** Different bots chat
	Bots like dependabot, github actions can talk a lot. Some coverage bot also appears a lot,
	although it is not chatty.
	Examples are [[https://github.com/yurake/k8s-3tier-webapp/pull/1773][yurake/k8s-3tier-webapp/pull/1773]], [[https://github.com/TomerFi/alexa-skill-shabbat-times/pull/197][TomerFi/alexa-skill-shabbat-times/pull/197]]

*** Github Actions bot complains about merge conflict
   Then some issues are flooded with comments from =app/github-actions=, stating that this PR might
   conflict with other PRs since they both edit =pom.xml=.

*** Github Actions bot complains about test failures
	In one PR, github actions bot flooded comments with test failures but devs seems do not care
	about them. It is not merged because dev came across other issues when upgrading.

	See [[https://github.com/nextcloud/android/pull/8136][android/pull/8136]] and [[https://github.com/Karumi/Shot/issues/188#issuecomment-801714576][Karumi/Shot/issues/188]].

	A fix was proposed in [[https://github.com/nextcloud/android/pull/8224/][nextcloud/android/pull/8224]].
	#+begin_src diff
import androidx.test.runner.AndroidJUnitRunner;
import com.karumi.shot.ShotTestRunner;

-public class ScreenshotTestRunner extends AndroidJUnitRunner {
+public class ScreenshotTestRunner extends ShotTestRunner {
 ...
         return super.newApplication(cl, className, context);
     }
-    @Override
-    public void onCreate(Bundle args) {
-        super.onCreate(args);
-        ScreenshotRunner.onCreate(this, args);
-    }
-
-    @Override
-    public void finish(int resultCode, Bundle results) {
-        ScreenshotRunner.onDestroy();
-        super.finish(resultCode, results);
-    }
 }
	#+end_src



*** Devs chat
	Should add a filter by stars. But the API for searching issues/PRs does not support filtering
	by number of stargazers. We need to first fetch all and then filter by looking into the repo.
	We will also need api tokens due to the rate limit.
	In some projects, devs left not so meaningful comments.

** Search PRs opened by dependabot and sort them by stars


** Check commits of PRs
   By filtering out PRs with 2 or more commits from previous search results (PRs authored by
   dependabot in Java projects), we have a shorter list of PRs to inspect.

   In lots of cases, commits other than the first one by dependabot are just merging commits.


*** TODO streamr-dev/streamr-client-java/pull/137
	In this PR, devs and bot contributed in total 41 commits, upgrading libraries and modifying
	build configurations and code.
*** TODO camunda-cloud/zeebe/pull/6659
	fix(deps): bump plexus-utils from 1.1 to 3.3.0

	Comments from one contributor explain why there is plexus-utils 1.1.
	#+begin_quote
	In Maven 3.x, if a plugin doesn't depend on plexus-utils it just pulls in 1.1
	#+end_quote

	So it is a strange behavior of maven introducing the dependency of such an old library. The
	contributor then added a new commit, specifying the plugin version as 3.3.0 and adding more
	related changes.

	Then CI build failed multiple times so that the contributor gave up and closed the PR.
	#+begin_quote
	Ugh, I had this working at some point, I guess I messed it up when I rebased?
	#+end_quote
	#+begin_quote
	Closing for now, not that important.
	#+end_quote

*** VERIFY heowc/SpringBootSample/pull/329
	Upgrade /grpc-spring-boot-starter/ from 4.2.3 to 4.3.0 causes =NoClassDefFoundError=.
	This was solved by library developers (in 4.3.1).

	+ Issues for for library: [[https://github.com/LogNet/grpc-spring-boot-starter/issues/169][grpc-spring-boot-starter/169]]
	+ Fixed in: [[https://github.com/LogNet/grpc-spring-boot-starter/commit/3ed3ff76b4d3fdcfcfb494ad725d1d8f2fd722ae][3ed3ff76b4d]]

*** CANCELED nextcloud/talk-android/pull/1060
	seems to be unrelated commits

*** VERIFY cloudfoundry/uaa/pull/1426
	It is a golang dependency, closed due to conflicts, but commenters did not indicate what the
	conflicts were.
	#+begin_quote
	Closing this PR without merge because trying to resolve the conflicts. Will wait for the next patch for this dependency.
	#+end_quote

*** CANCELED nextcloud/talk-android/pull/1060
	Bump appcompat from 1.2.0-alpha01 to 1.3.0-beta01
	#+begin_quote
	ignore non-stable lib releas(es)
	#+end_quote

*** CANCELED quarkusio/quarkus/pull/16566
	Bump testcontainers-bom from 1.15.2 to 1.15.3

	Maven enforcer is used, and this upgrade would trigger failure when checking depndency convergence.

	#+begin_quote
	there is a convergence problem with docker-java-api in various modules (the ones in which you
	introduced strimzi, AFAICS)
	#+end_quote

   An example:
   #+begin_src sh
--- maven-enforcer-plugin:3.0.0-M3:enforce (enforce) @ quarkus-integration-test-kafka-ssl ---
[WARNING]
Dependency convergence error for com.github.docker-java:docker-java-api:3.2.8 paths to dependency are:
+-io.quarkus:quarkus-integration-test-kafka:999-SNAPSHOT
  +-io.strimzi:strimzi-test-container:0.22.1
    +-org.testcontainers:testcontainers:1.15.3
      +-com.github.docker-java:docker-java-api:3.2.8
and
+-io.quarkus:quarkus-integration-test-kafka:999-SNAPSHOT
  +-io.strimzi:strimzi-test-container:0.22.1
    +-com.github.docker-java:docker-java-api:3.2.7
   #+end_src

   In this case, there was not a direct dependency to =testcontainers=, (although
   =testcontainers-bom= is imported in BOM of this project), instead, it was introduced by
   =strimzi-test-container=. In the same time, it seems that they do not actually need
   =testcontainers= for =strimzi-test-container= but they need it for maybe some other
   functionalities of this project.

   This PR got merged after a fix from developer which excluded =testcontainers= for =strimzi= and
   adding direct dependencies to =testcontainers= in several POMs.

*** CANCELED JabRef/jabref/pull/7405
	An uninteresting case. The second commit is that devs change the upgrading targets from latest
	versions on development branch to stable versions.
*** CANCELED OpenRefine/OpenRefine/pull/3803
	+ It is an upgrade to a npm package
	+ The second commit is a merge, modifying =yarn.lock=, which included corresponding changes due
      to dependency bumps in =package.json=.
	+ The PR was closed due to unknown reason
	  - very possibly due to CI check failures, since the failed check is /Test with Cypress on
        chrome/, in accordance with the upgraded pakcage "cypress-file-upload".

*** CANCELED RIPE-NCC/whois/pull/703
	+ Dependabot: Bump groovy from 2.5.13 to 3.0.6.
	+ Dev: Also upgrade spock framework.
	+ Dev: Revert spock upgrade because integration tests failed

*** CANCELED Marketcetera/marketcetera/pull/22
	+ Bot: upgrade guice
	+ Dev: remove unneeded dependency

** Filter high starred repos

* Check Rust Projects
** Search PRs with 2+ commits
*** CANCELED libp2p/rust-libp2p/pull/1960
	Update yamux requirement from 0.8.0 to 0.9.0.

	It got merged. The bot only updated =muxers/yamux/Cargo.toml= while devs also updated
	libp2p-yamux in root =Cargo.toml= accordingly and edited changelog.

	And there are some discussions about transitive dependencies dropping support for some
	platforms.

*** CANCELED libp2p/rust-libp2p/pull/1751
	Update asn1_der requirement from 0.6.1 to 0.7.1.
	(also check #2000 which handled breaking changes and superseded this PR)

	This is a single library issue.

*** CANCELED rusty-celery/rusty-celery/pull/194
	Update tokio requirement from 0.2.13 to 0.3.0. (also check #195 and [[https://github.com/tokio-rs/tokio/issues/2965][tokio/2965]])

	Single library API change issue.

*** CANCELED mobilecoinfoundation/mobilecoin/pull/516
	Bump rusoto_core from 0.42.0 to 0.45.0. (also check #516)

	Need to also update =rusoto_s3=, otherwise two versions of =rusoto_core= co-exist.

	#+begin_src
+ mc-ledger-distribution v1.0.0
|--+ rusoto_core v0.42.0
\--+ rusoto_s3 v0.42.0
   \---rusoto_core v0.42.0
	#+end_src

	Cargo supports multiple versions of the same library through name mangling, but doing so can
	lead to potential problems.

	=0.42.0= and =0.45.0= are seen as semver-incompatible versions by cargo. So cargo could not
	choose a version in the compatible range, instead, both versions would be used and this
	could lead to issues (see [[https://doc.rust-lang.org/cargo/reference/resolver.html#version-incompatibility-hazards][version incompatibility hazards]]).

	It seems that developers thought that not upgrading both caused problems here.

	This PR was closed because of breaking changes.
	#+begin_quote
	Unfortunately they no longer support sync operations. Everything returns an async Future and you
	need to have a Tokio runtime to get it to execute.
	#+end_quote

*** WAIT Epiphany-platform/CommonDataLayer/pull/124
	Bump prost from 0.6.1 to 0.7.0

	complex issue, superseded by #137 which upgraded tokio to 1.0.

*** VERIFY rusty-celery/rusty-celery/pull/217
	Update tokio requirement from 0.3.6 to 1.0.0
	It was superseded by #223.

	Commit =676fcba0= also upgrade tokio-amqp.
	#+begin_src diff
diff --git a/Cargo.toml b/Cargo.toml
index 4dedaca..3ec0cf8 100644
--- a/Cargo.toml
+++ b/Cargo.toml
@@ -35,7 +35,7 @@ serde-pickle = { version = "0.6", optional = true }
 thiserror = "1.0"
 async-trait = "0.1"
 lapin = "1.6.5"
-tokio-amqp = "0.3.1"
+tokio-amqp = "1.0.0"
 log = "0.4"
 futures = { version = "0.3", features = ["async-await"] }
 uuid = { version = "0.8", features = ["v4"]}
	#+end_src
	Commit =1a19fbaf= added dependency on tokio-stream, which had been part of tokio.
	Also comes with API changes in tokio-stream.
#+begin_src diff
diff --git a/Cargo.toml b/Cargo.toml
index 3ec0cf8..42f4b98 100644
--- a/Cargo.toml
+++ b/Cargo.toml
@@ -26,6 +26,7 @@ name = "celery_app"
 [dependencies]
 chrono = { version = "0.4", features = ["serde"] }
 tokio = { version = "1.0.0", features = ["full"]}
+tokio-stream = "0.1.0"
 serde = { version = "1.0", features = ["derive"]}
 serde_json = "1.0"
 rmp-serde = { version = "0.15", optional = true }
diff --git a/src/app/mod.rs b/src/app/mod.rs
index ab9bdcd..035edbd 100644
--- a/src/app/mod.rs
+++ b/src/app/mod.rs
@@ -10,10 +10,10 @@ use tokio::select;
 #[cfg(unix)]
 use tokio::signal::unix::{signal, Signal, SignalKind};

-use tokio::stream::StreamMap;
 use tokio::sync::mpsc::{self, UnboundedSender};
 use tokio::sync::RwLock;
 use tokio::time::{self, Duration};
+use tokio_stream::StreamMap;

 mod trace;

@@ -611,7 +611,7 @@ where
                     info!("Warm shutdown...");
                     break;
                 },
-                maybe_task_event = task_event_rx.next() => {
+                maybe_task_event = task_event_rx.recv() => {
                     if let Some(event) = maybe_task_event {
                         debug!("Received task event {:?}", event);
                         match event {
@@ -620,7 +620,7 @@ where
                         };
                     }
                 },
-                maybe_broker_error = broker_error_rx.next() => {
+                maybe_broker_error = broker_error_rx.recv() => {
                     if let Some(broker_error) = maybe_broker_error {
                         error!("{}", broker_error);
                         return Err(broker_error.into());
@@ -648,7 +648,7 @@ where
                             return Err(CeleryError::ForcedShutdown);
                         }
                     },
-                    maybe_event = task_event_rx.next() => {
+                    maybe_event = task_event_rx.recv() => {
                         if let Some(event) = maybe_event {
                             debug!("Received task event {:?}", event);
                             match event {
@@ -699,10 +699,10 @@ impl Ender {
         let sigtype;

         select! {
-            _ = self.sigint.next() => {
+            _ = self.sigint.recv() => {
                 sigtype = SigType::Interrupt
             },
-            _ = self.sigterm.next() => {
+            _ = self.sigterm.recv() => {
                 sigtype = SigType::Terminate
             }
         }
#+end_src

	Up to now, there were still build failures since =try_recv()= is not avaliable any more.
	See [[https://docs.rs/tokio/0.3.7/tokio/sync/mpsc/struct.Receiver.html#method.try_recv][tokio::sync::mpsc::Receiver#try_recv]]

	Another commit =1d869ad6= fixed this by upgrading redis version and replacing the method call.
	#+begin_src diff
diff --git a/Cargo.toml b/Cargo.toml
index 42f4b98..be4322a 100644
--- a/Cargo.toml
+++ b/Cargo.toml
@@ -47,10 +47,7 @@ once_cell = { version = "1.3.1" }
 globset = "0.4"
 hostname = "0.3.0"

-[dependencies.redis]
-git = "https://github.com/mitsuhiko/redis-rs.git"
-rev="8088a59"
-features=["connection-manager", "tokio-comp"]
+redis = { version="0.19.0", features=["connection-manager", "tokio-comp"] }

 [dev-dependencies]
 rmp-serde = "0.15"
diff --git a/src/broker/redis.rs b/src/broker/redis.rs
index 15306b5..21966bb 100644
--- a/src/broker/redis.rs
+++ b/src/broker/redis.rs
@@ -313,7 +313,10 @@ impl Broker for RedisBroker {
         let (channel, delivery) = delivery;
         channel.remove_task(delivery).await?;
         let mut waker_rx = self.waker_rx.lock().await;
-        if let Ok(waker) = waker_rx.try_recv() {
+        // work around for try_recv. We do not care if a waker is available after this check.
+        let dummy_waker = futures::task::noop_waker_ref();
+        let mut dummy_ctx = std::task::Context::from_waker(dummy_waker);
+        if let Poll::Ready(Some(waker)) = waker_rx.poll_recv(&mut dummy_ctx) {
             waker.wake();
         }
         Ok(())
	#+end_src


	We are curious about the actual changes of the redis upgrade (from '8088a59' to '0.19.0'),
	and the corresponding PR is [[https://github.com/mitsuhiko/redis-rs/pull/428/commits/4196019494aafc2bab718bafd1fdfd5e8c195ffa][redis-rs/pull/428]]


*** CANCELED whamcloud/integrated-manager-for-lustre/pull/951
	closed. Some checks were not successful, reason unknown (CI page 404).

*** CANCELED diem/diem/pull/5991
	Merged. Javascript dependencies, uninteresting case.

*** CANCELED petabi/eventio/pull/37
	Superseded by #39, where devlopers manually upgraded and made essential changes.

	Single dependency issue.

*** WAIT epiphany-platform/CommonDataLayer/pull/123

	Same as [[Epiphany-platform/CommonDataLayer/pull/124]]

*** CANCELED iqlusioninc/yubikey-piv.rs/pull/184
	#+begin_quote
	CI build failing since there's two different versions of =nom= being used so won't be able to
	update until x509-parser also updates that dep.
	#+end_quote

	Another PR ([[https://github.com/iqlusioninc/yubikey-piv.rs/pull/194/][#194]]) bumps der-parser, nom, x509-parser together.

*** CANCELED spenserblack/check-latest-rs/pull/16
	Update tokio requirement from 0.2 to 0.3.

	The second commit is to enable a feature after upgrading tokio.

*** WAIT diem/diem/pull/7032
	Bump kube from 0.42.0 to 0.44.0.

	The second commit updated another dependency =k8s-openapi= in =testsuite/cluster-test=.


** Why incompat issues involving multi-libraries rarely found in dependabot PRs
   Deep issues are not exposed and devls are stopped by trivial errors such as build failures,
   SymbolNotFound errors (in Java) and unsatisfying dependency errors (in some lang w/ modern pkg
   management).
