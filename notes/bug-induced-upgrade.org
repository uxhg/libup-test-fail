#+TITLE: Bug-induced Upgrade
#+DATE:
#+AUTHOR: wuxh
#+OPTIONS: timestamp:nil
#+OPTIONS: ^:{}
#+HTML_HEAD_EXTRA: <style type="text/css">body{font-family:"Iowan Old Style","Palatino","Linux Libertine","Georgia", serif;} code, kbd, pre, samp {font-family: Monaco, Consolas, "Cascadia Code", "Fira Mono", "Fira Code", monospace}</style>



* Overview
** Goal
   There exist some library upgrade which would break client. Among them lots of cases are due to
   the co-evolution of libraries. We aim to find those bug-induced upgrade.

   Given a client (and its dependencies), generate a patch on POM to upgrade a certain library / certain libraries,
   so that some client tests (used to pass) would fail with upgraded dependencies.

** NaÃ¯ve approach / groundtruth
   Upgrade each library and run tests.
   Our approach should be more efficient than this brute-force approach.
** Current idea
   To reduce the cycles of upgrade-runtest,
   cluster / partition all dependencies (maybe include transitive) as weakly-connected (directed) sub-graphs,
   so that multiple combinations can be pruned after one upgrade-runtest cycle.

** Algorithm
   #+begin_src C
// INPUT: c - a client
D_a = DependencyGraph(c) // pom
D_b = RunAnalysis() // codeQL query
G = ConstructGraph(D_a, D_b)
G_0, ..., G_n = Partition(G) // a set of sub-graphs
While (any of G_i is not empty) do
    For i = 0 to n do
	L_i = Prioritise(G_i)
    done
    DoUpgrade([L_i for i = 0 to n])
    T = SelectTest()
    suc, trace = RunTest(T)
    if suc is false then
	if Verify(trace) is true then
	    return
    else
	Prune(G_0, ..., G_n)
done
   #+end_src

** How to reduce search space

** Client issues
* Partition strategy / ideas
** Mine references used in POMs
   Those library whose versions are configured use the same reference should have strong
   connection.
** Static analysis on client
   Find highly-related libraries, based on their mutual presence and/or data dependency in a
   client method.

* Interaction Pattern (where conflicts happen)
+ JAR ?
+ POM:
+ data: e.g. jacoco-core, jacoco-report
+ client usage
* Future Plan
+ Upgrade pairs to find conflicts caused by two (or more) dependencies


* Maven Dependency Plugin
** Verbose option
   =-Dverbose= option was removed since =maven-dependency-plugin:3.0= for Maven 3 compatibility.
** copy-dependency

** unpack-dependencies
   We could use this option to directly unpack jars instead of doing it manually.

* Dataflow Analysis with CodeQL
** Step
#+begin_src sh
codeql database create project.db --language=java
codeql database analyze project.db ~/codeql-repo/java/ql/src/datadp.ql  --output=/tmp/a.csv --format=csv
codeql bqrs decode --format=csv -o project.csv project.db/results/codeql-java/datadp.bqrs
#+end_src
** Current issues (but can be solved in the merging step)
   + [X] Not filter client class: can do it in the later steps
   + [ ] Filter java std lib (why =notJavaLib/1= is not applied on =isSink/1=)
   + [X] Not work when using codeql command line tools (path-problem result patterns?)
	 - refer to [[#manual-decode-bqrs]] for solutions
   + [ ] Can =notSameJar/2= be improved?

** How to get query results with CLT
   :PROPERTIES:
   :CUSTOM_ID: manual-decode-bqrs
   :END:
When the query does not conform with the format of path query, =interpret-results= does not work.
However, we can always invoke =bqrs decode --format=csv -o results.csv datadp.bqrs=, generating a
CSV of query results.

** CodeQL Dataflow Analysis for Java
   Refer to [[https://codeql.github.com/docs/codeql-language-guides/analyzing-data-flow-in-java/][CodeQL Java Guide: analyzing-data-flow]]

   + =java.dataflow.DataFlow= implements *local* dataflow analysis
   + =java.dataflow.DataFlow::Configuration= implements *global* dataflow analysis
   + =java.dataflow.TaintTracking= implements *local* taint tracking
	 - the analysis is performed using predicate =TaintTracking::localTaint(Dataflow::Node, Dataflow::Node)=
	 - the predicate is actually a transitive closure of =localTaintStep/2=
   + =java.dataflow.TaintTracking::Configuration= implements *global* taint tracking
	 - the analysis is performed using predicate =hasFlow(Dataflow::Node, Dataflow::Node)=
** Precision

* Add dataflow analysis results in pomdep graph
** Multiple G-A-V in one JAR
   + (fuzzy) match class path against group_id/artifact_id
     - now: split by dot and do set intersection (class_name in csv ^ class_path in JAR)
** On determining Mvn-Coord of a JAR
   + Some JAR do not include =pom.properties=
   + Some JAR do not include =META-INF= directory, at least =MANIFEST.MF= can be used to determine artifact id
   + If found nothing, just use the JAR name
	 - [ ] can at least prune version string

** Match coord with nodes in pomdep graph
   + full match (g,a,v) first
   + if failed, match artifact_id only
   + if failed, skip


* Class-level graph
  + [ ] Classes in which package
  + [ ] Class reference: datalog


* Cases Inspection
** java-driver
   + On the target version (tag =4.3.0=), expected dependency
   =slf4j.LoggerFactory -> logback.classic.Logger= does not appear in
   codeql query results.

   + Modify query script with location report.

   + Try to checkout to newer version =4.9.0=, run the same query again,
   found similar dependency in another file.

[[file:../../cases/java-driver-again/core/src/test/java/com/datastax/oss/driver/internal/core/util/LoggerTest.java][java-driver:4.9.0 LoggerTest]]
#+begin_src java
// 4.9.0 (023278b183e48b2d515b6b85c54e5f446a7addb9)
// core/src/test/java/com/datastax/oss/driver/internal/core/util/LoggerTest.java
public static LoggerSetup setupTestLogger(Class<?> clazz, Level levelToCapture) {
  @SuppressWarnings("unchecked")
  Appender<ILoggingEvent> appender = (Appender<ILoggingEvent>) mock(Appender.class);

  ArgumentCaptor<ILoggingEvent> loggingEventCaptor = ArgumentCaptor.forClass(ILoggingEvent.class);
  Logger logger = (Logger) LoggerFactory.getLogger(clazz); // line no: 33
  Level originalLoggerLevel = logger.getLevel();
  logger.setLevel(levelToCapture);
  logger.addAppender(appender); // line no: 36
  return new LoggerSetup(appender, originalLoggerLevel, logger, loggingEventCaptor);
}
#+end_src

which results in:
#+begin_src
"mock(...)","org.mockito.Mockito","addAppender(...)","ch.qos.logback.classic.Logger","LoggerTest:30[66-85]","LoggerTest:36[24-31]"
"getLogger(...)","org.slf4j.LoggerFactory","getLevel(...)","ch.qos.logback.classic.Logger","LoggerTest:33[30-59]","LoggerTest:34[33-38]"
"getLogger(...)","org.slf4j.LoggerFactory","setLevel(...)","ch.qos.logback.classic.Logger","LoggerTest:33[30-59]","LoggerTest:35[5-10]"
"getLogger(...)","org.slf4j.LoggerFactory","addAppender(...)","ch.qos.logback.classic.Logger","LoggerTest:33[30-59]","LoggerTest:36[5-10]"
"getLevel(...)","ch.qos.logback.classic.Logger","new LoggerSetup(...)","com.datastax.oss.driver.internal.core.util.LoggerTest$LoggerSetup","LoggerTest:34[33-49]","LoggerTest:37[38-56]"
#+end_src


But the following code (=DefaultLoadBalancingPolicyTestBase.java=) in both versions did not result in a record in query results:
[[file:../../cases/java-driver-430/core/src/test/java/com/datastax/oss/driver/internal/core/loadbalancing/DefaultLoadBalancingPolicyTestBase.java][java-driver:4.3.0 LoggerTest]]
#+begin_src java
// 4.3.0 (4af0061baabe1bcc03a9a6eea0028c12a6bd2e88)
// core/src/test/java/com/datastax/oss/driver/internal/core/loadbalancing/DefaultLoadBalancingPolicyTestBase.java
@Before
  public void setup() {
    ...
    logger =
        (Logger) LoggerFactory.getLogger("com.datastax.oss.driver.internal.core.loadbalancing");
    logger.addAppender(appender);  // line no: 81
    ...
  }
#+end_src

*** WAIT Differences of those two code snippets
	+ In the /not-captured/ code, =logger= and =appender= was declared and initialized through
	  mocking outside of the method.
	  And in the successfully recognized example, both are local variables.
	  Note that in CodeQL we already use a global taint tracking.

	+ Using a test script (see [[codeql-test][below]], we can confirm that 2 (different) qualified
    names are correctly recognized. The problem seems to stem from codeql's =hasFlow/2=.

*** Remove JUnit decorators
	We try to remove JUnit annotations.

**** Remove @Before only
	 Running the following script in =java-driver/core=.
	 #+begin_src sh
rg -l '\s+@Before' -t java | xargs -I '{}'  sed -i -r -e 's/^(\s+)(@Before)/\1\/\/\2/g' {}
	 #+end_src
	 It may trigger some errors from format-enforcing plugin, can be resolved by run code formatting.

	 Then it still lead to build failure.
	 #+begin_src
[JUnit4SetUpNotRun] setUp() method will not be run; please add JUnit's @Before annotation
	 #+end_src

	 

** chaos-monkey-spring-boot
#+begin_src java
@Before
public void setUp() {
	ch.qos.logback.classic.Logger root = (ch.qos.logback.classic.Logger) LoggerFactory.getLogger(ch.qos.logback.classic.Logger.ROOT_LOGGER_NAME);
	root.addAppender(mockAppender);

	captorLoggingEvent = ArgumentCaptor.forClass(LoggingEvent.class);
}
#+end_src

A simple codeql program (see [[codeql-test][below]]) for testing show that the code got processed and class names are
recognized correctly.

#+NAME: codeql-test
#+begin_src sql
import java
from Call a, Expr s, Location sl
where s = a.getQualifier() and sl = s.getLocation()
select a.getCallee().getDeclaringType().getQualifiedName(), s, sl
#+end_src

#+begin_src sql
"org.slf4j.LoggerFactory","LoggerFactory","KillAppAssaultTest:51[78-90]"
"ch.qos.logback.classic.Logger","root","KillAppAssaultTest:52[9-12]"
#+end_src

It seems that JUnit annotations interfere with dataflow analysis of CodeQL. 
Following is a change which would make the codeql program for dataflow detection work.
#+begin_src diff
@@ -46,7 +46,7 @@ public class KillAppAssaultTest {
     @Mock
     private MetricEventPublisher metricsMock;
 
-    @Before
+    // @Before
     public void setUp() {
         ch.qos.logback.classic.Logger root = (ch.qos.logback.classic.Logger) LoggerFactory.getLogger(ch.qos.logback.classic.Logger.ROOT_LOGGER_NAME);
         root.addAppender(mockAppender);
@@ -54,8 +54,9 @@ public class KillAppAssaultTest {
         captorLoggingEvent = ArgumentCaptor.forClass(LoggingEvent.class);
     }
 
-    @Test
+    // @Test
     public void killsSpringBootApplication() {
+        setUp();
         KillAppAssault killAppAssault = new KillAppAssault(null, metricsMock);
         killAppAssault.attack();
#+end_src


** Current Solution
   Use =DataFlow::Configuration= instead of =TaintTracking::Configuration=.
   Refer to [[https://github.com/github/codeql/issues/5511][github/codeql:issue:5511]].

*** What are the differences?
	Compared with =DataFlow::Configuration=, the =TaintTracking::Configuration= extends global
	dafaflow by including non-value-preserving flow steps.

* TODO Version Conflicts Discovery
** Track change history of library
   
** Handle injections
   DI pushes the =NoClassDef= to runtime.



* Run on all cases
  
